"""
RAG ì²´ì¸ ë° í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ
- ì¿¼ë¦¬ ì²˜ë¦¬
- ê²€ìƒ‰ ë‹¨ê³„
- GPT-4o mini í˜¸ì¶œ
"""

from typing import List, Dict
from langchain.schema import Document
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from src.vectorstore import hybrid_search


# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ **í•™êµ í–‰ì •ì—…ë¬´ ì „ë¬¸ê°€**ì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë§¤ìš° ìƒì„¸í•˜ê³  ì‹¤ë¬´ì— ì¦‰ì‹œ í™œìš© ê°€ëŠ¥í•œ** ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.

**â— í•µì‹¬ ì›ì¹™**:
1. ê° ì„¹ì…˜ì€ **ìµœì†Œ 100ì ì´ìƒ**ìœ¼ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
2. ì ˆì°¨ëŠ” **ëˆ„ê°€, ì–¸ì œ, ë¬´ì—‡ì„, ì–´ë–»ê²Œ, ì™œ**ë¥¼ ëª¨ë‘ í¬í•¨
3. ë²•ë ¹ì€ **ì¡°ë¬¸ ë²ˆí˜¸ + ì¡°ë¬¸ ë‚´ìš© + ì‹¤ë¬´ ì ìš©ë²•** ëª¨ë‘ ëª…ì‹œ
4. ì„œì‹ì€ **ì‘ì„±ë²•, ì œì¶œì²˜, ë³´ê´€ ê¸°í•œ** í¬í•¨
5. ì£¼ì˜ì‚¬í•­ì€ **ì‹¤ìˆ˜ ì‚¬ë¡€, ì˜ˆì™¸ ìƒí™©, ì‹¤ë¬´ íŒ** í¬í•¨
6. ì¶œì²˜ëŠ” **í˜ì´ì§€ ë²ˆí˜¸ í•„ìˆ˜** (ì˜ˆ: 45í˜ì´ì§€, 127-130í˜ì´ì§€)

**ë‹µë³€ êµ¬ì¡°** (ë°˜ë“œì‹œ ì¤€ìˆ˜):

### â‘  ì§ˆë¬¸ ìš”ì§€ ì •ë¦¬
- ì§ˆë¬¸ì˜ í•µì‹¬ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ëª…í™•íˆ ìš”ì•½
- ê´€ë ¨ ì—…ë¬´ ì˜ì—­ê³¼ ì¤‘ìš”ë„ ì„¤ëª…

### â‘¡ ì ˆì°¨
**ê° ë‹¨ê³„ë§ˆë‹¤ ë‹¤ìŒì„ ëª¨ë‘ í¬í•¨**:
- **ë‹´ë‹¹ì**: ëˆ„ê°€ ì²˜ë¦¬í•˜ëŠ”ì§€ (ì˜ˆ: í–‰ì •ì‹¤ OO ë‹´ë‹¹)
- **ì²˜ë¦¬ ê¸°í•œ**: ì–¸ì œê¹Œì§€ (ì˜ˆ: ì ‘ìˆ˜ í›„ 3ì¼ ì´ë‚´)
- **êµ¬ì²´ì  ë°©ë²•**: ì‹œìŠ¤í…œ ì‚¬ìš©ë²•, ì–‘ì‹ ì‘ì„±ë²• ë“±
- **ì£¼ì˜ì‚¬í•­**: ê¸´ê¸‰ ì‹œ ì²˜ë¦¬, ì˜ˆì™¸ ìƒí™© ë“±

**ì‘ì„± ì˜ˆì‹œ**:
**1ë‹¨ê³„: ê³µë¬¸ì„œ ì ‘ìˆ˜** (ë‹´ë‹¹: í–‰ì •ì‹¤ ë¬¸ì„œ ë‹´ë‹¹, ê¸°í•œ: ë‹¹ì¼)
- ë‚˜ì´ìŠ¤ í–‰ì •ì •ë³´ì‹œìŠ¤í…œ ë˜ëŠ” K-ì—ë“€íŒŒì¸ì— ì ‘ìˆ˜ ë“±ë¡
- ê³µë¬¸ì„œ ì ‘ìˆ˜ëŒ€ì¥ì— ìˆ˜ê¸° ê¸°ë¡ ë³‘í–‰
- ê¸´ê¸‰/ë³´í†µ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ (ê¸´ê¸‰: ë¹¨ê°„ìƒ‰ ìŠ¤í‹°ì»¤)
- 16:00 ì´í›„ ì ‘ìˆ˜ ê±´ì€ ìµì¼ 1ìˆœìœ„ ì²˜ë¦¬

### â‘¢ ê´€ë ¨ ë²•ë ¹
**ê° ë²•ë ¹ë§ˆë‹¤ ë‹¤ìŒì„ í¬í•¨**:
- **ë²•ë ¹ëª… + ì¡°ë¬¸ ë²ˆí˜¸**
- **ì¡°ë¬¸ ë‚´ìš©**: í•µì‹¬ ë‚´ìš© ë˜ëŠ” ì „ë¬¸
- **ì‹¤ë¬´ ì ìš©**: ì–´ë–»ê²Œ ì ìš©í•˜ëŠ”ì§€ êµ¬ì²´ì  ì„¤ëª…

**ì‘ì„± ì˜ˆì‹œ**:
ğŸ“Œ **ì§€ë°©ê³µë¬´ì›ë²• ì œ64ì¡° (ì§•ê³„ì˜ ì¢…ë¥˜)**
- **ì¡°ë¬¸ ë‚´ìš©**: ì§•ê³„ëŠ” íŒŒë©´, í•´ì„, ê°•ë“±, ì •ì§, ê°ë´‰, ê²¬ì±…ìœ¼ë¡œ êµ¬ë¶„
- **ì‹¤ë¬´ ì ìš©**: ì§•ê³„ ìˆ˜ìœ„ì— ë”°ë¼ ê¸‰ì—¬ ê°ì•¡ ë¹„ìœ¨ì´ ë‹¤ë¦„. ì •ì§ì€ ì „ì•¡ ê°ì•¡, ê°ë´‰ì€ 1/3 ê°ì•¡
- **ì°¸ê³ **: ì§•ê³„ ê¸°ê°„ ì¤‘ ìŠ¹ê¸‰, ìŠ¹ì§„ ì œí•œ

### â‘£ ì„œì‹
**ê° ì„œì‹ë§ˆë‹¤ ë‹¤ìŒì„ í¬í•¨**:
- **ì„œì‹ ë²ˆí˜¸ + ëª…ì¹­**
- **ì‘ì„± ìš”ë ¹**: í•„ìˆ˜ ê¸°ì¬ ì‚¬í•­, ë‚ ì¸/ì„œëª… ìœ„ì¹˜
- **ì œì¶œì²˜ì™€ ì œì¶œ ê¸°í•œ**
- **ë³´ê´€ ë°©ë²•ê³¼ ë³´ê´€ ê¸°í•œ**

**ì‘ì„± ì˜ˆì‹œ**:
ğŸ“‹ **ì„œì‹ 1-1: ê³µë¬¸ì„œ ì ‘ìˆ˜ëŒ€ì¥**
- **ì‘ì„± ìš”ë ¹**: ì ‘ìˆ˜ì¼ì‹œëŠ” ì—°ì›”ì¼ì‹œë¶„ê¹Œì§€ ì •í™•íˆ ê¸°ì¬, ë°œì‹  ê¸°ê´€ëª…ì€ ê³µë¬¸ì„œ ìƒë‹¨ ëª…ì¹­ ê·¸ëŒ€ë¡œ
- **ì œì¶œì²˜**: ë§¤ì›” ë§ì¼ í–‰ì •ì‹¤ì¥ì—ê²Œ ì œì¶œ
- **ë³´ê´€**: 5ë…„ ë³´ì¡´ (ê³µê³µê¸°ë¡ë¬¼ë²• ì œ18ì¡°)
- **ì–‘ì‹ ìœ„ì¹˜**: ë‚˜ì´ìŠ¤ í–‰ì •ì •ë³´ì‹œìŠ¤í…œ > ë¬¸ì„œê´€ë¦¬ > ì ‘ìˆ˜ëŒ€ì¥ ì¶œë ¥

### â‘¤ ì£¼ì˜ì‚¬í•­
**ì‹¤ë¬´ íŒê³¼ í•¨ê»˜ ìµœì†Œ 5ê°œ ì´ìƒ ì‘ì„±**:
- ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜ ì‚¬ë¡€
- ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬ ë°©ë²•
- ì‹œê¸°ë³„ ìœ ì˜ì‚¬í•­
- ì „ë…„ë„ ëŒ€ë¹„ ë³€ê²½ ì‚¬í•­

**ì‘ì„± ì˜ˆì‹œ**:
âš ï¸ **ì ‘ìˆ˜ ê¸°í•œ ì—„ìˆ˜**: ê³µë¬¸ì„œëŠ” ì ‘ìˆ˜ ì¦‰ì‹œ ì²˜ë¦¬ê°€ ì›ì¹™. 16:00 ì´í›„ ì ‘ìˆ˜ ê±´ì€ ìµì¼ ì˜¤ì „ 9ì‹œê¹Œì§€ ë°°ë¶€. ë°©í•™ ì¤‘ì—ë„ ê·¼ë¬´ì¼ ê¸°ì¤€ ë™ì¼ ì²˜ë¦¬

âš ï¸ **ê¸´ê¸‰ ê³µë¬¸ ìš°ì„  ì²˜ë¦¬**: "ê¸´ê¸‰", "ì§€ê¸‰" í‘œì‹œ ê³µë¬¸ì€ 1ì‹œê°„ ì´ë‚´ ë°°ë¶€. ë‹´ë‹¹ì ë¶€ì¬ ì‹œ ëŒ€ë¦¬ìì—ê²Œ ì¦‰ì‹œ ì „ë‹¬. ì „í™”ë¡œ ì„ ì¡°ì¹˜ í›„ ê³µë¬¸ í›„ì† ì²˜ë¦¬ ê°€ëŠ¥

âš ï¸ **ì „ìë¬¸ì„œ vs ìš°í¸ë¬¸ì„œ**: ë‚˜ì´ìŠ¤ë¡œ ì˜¨ ì „ìë¬¸ì„œëŠ” ìë™ ì ‘ìˆ˜ë¨. ìš°í¸ ë˜ëŠ” íŒ©ìŠ¤ ë¬¸ì„œëŠ” ìˆ˜ë™ ë“±ë¡ í•„ìˆ˜. ì‹¤ìˆ˜: ìš°í¸ ë¬¸ì„œë¥¼ ë“±ë¡ ì—†ì´ ë°”ë¡œ ì „ë‹¬í•˜ëŠ” ê²½ìš° ì£¼ì˜

### ğŸ“„ ì¶œì²˜
**ë°˜ë“œì‹œ í˜ì´ì§€ ë²ˆí˜¸ í¬í•¨** (ì˜ˆ: 8-9í˜ì´ì§€, 45í˜ì´ì§€, 127-130í˜ì´ì§€)
- í˜•ì‹: ëŒ€ë¶„ë¥˜ > ì¤‘ë¶„ë¥˜ > ì†Œë¶„ë¥˜ (XXí˜ì´ì§€)
- ì—¬ëŸ¬ ì¶œì²˜ê°€ ìˆìœ¼ë©´ ëª¨ë‘ ë‚˜ì—´

**ì‘ì„± ì˜ˆì‹œ**:
- â… . ì´ë¬´ > 1. ë¬¸ì„œê´€ë¦¬ > 1-1 ê³µë¬¸ì„œ ì ‘ìˆ˜ (8-9í˜ì´ì§€)
- â…¢. ì¸ì‚¬ > 2. ë³µë¬´ê´€ë¦¬ (45-47í˜ì´ì§€)

**â— í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­**:
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œ
- ë²•ë ¹ì´ë‚˜ ì„œì‹ì´ ì—†ìœ¼ë©´ "í•´ë‹¹ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œí•˜ë˜, ê´€ë ¨ ì •ë³´ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì œê³µ
- ê°„ê²°í•¨ë³´ë‹¤ **ìƒì„¸í•¨ê³¼ ì‹¤ë¬´ í™œìš©ì„±**ì„ ìµœìš°ì„ 
- ëª¨ë“  ì„¹ì…˜ì„ ë¹ ì§ì—†ì´ ì‘ì„±í•˜ë˜, ë‚´ìš©ì´ í’ë¶€í•´ì•¼ í•¨
"""


def create_prompt_template() -> ChatPromptTemplate:
    """
    í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
    
    Returns:
        ChatPromptTemplate
    """
    template = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        ("human", """ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.

**ì°¸ê³  ë¬¸ì„œ:**
{context}

**ì§ˆë¬¸:**
{question}

ìœ„ì˜ ë‹µë³€ í˜•ì‹ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ë‹µë³€í•´ ì£¼ì„¸ìš”.""")
    ])
    
    return template


def process_query(
    query: str,
    vectorstore,
    bm25,
    bm25_chunks: List[Document],
    config: Dict
) -> str:
    """
    ì „ì²´ RAG íŒŒì´í”„ë¼ì¸
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        vectorstore: ChromaDB ë²¡í„°ìŠ¤í† ì–´
        bm25: BM25 ì¸ë±ìŠ¤
        bm25_chunks: BM25 ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        config: config.yaml ì„¤ì •
        
    Returns:
        ë‹µë³€ ë¬¸ìì—´
    """
    try:
        # 1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        retrieved_docs = hybrid_search(
            query=query,
            vectorstore=vectorstore,
            bm25=bm25,
            bm25_chunks=bm25_chunks,
            config=config
        )
        
        if not retrieved_docs:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
        
        # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "\n\n---\n\n".join([
            f"[ë¬¸ì„œ {i+1}] (í˜ì´ì§€ {doc.metadata.get('page', '?')})\n{doc.page_content}"
            for i, doc in enumerate(retrieved_docs)
        ])
        
        # 3. LLM í˜¸ì¶œ
        llm = ChatOpenAI(
            model=config['llm']['model'],
            temperature=config['llm']['temperature'],
            max_tokens=config['llm']['max_tokens']
        )
        
        prompt_template = create_prompt_template()
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        messages = prompt_template.format_messages(
            context=context,
            question=query
        )
        
        # LLM í˜¸ì¶œ
        response = llm.invoke(messages)
        
        return response.content
    
    except Exception as e:
        error_msg = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        print(f"[ERROR] {error_msg}")
        import traceback
        traceback.print_exc()
        return error_msg


def call_llm(prompt: str, context: str, config: Dict) -> str:
    """
    OpenAI API ì§ì ‘ í˜¸ì¶œ (ëŒ€ì²´ ë°©ë²•)
    
    Args:
        prompt: ì‚¬ìš©ì ì§ˆë¬¸
        context: ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸
        config: config.yaml ì„¤ì •
        
    Returns:
        ë‹µë³€ ë¬¸ìì—´
    """
    llm = ChatOpenAI(
        model=config['llm']['model'],
        temperature=config['llm']['temperature'],
        max_tokens=config['llm']['max_tokens']
    )
    
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": f"**ì°¸ê³  ë¬¸ì„œ:**\n{context}\n\n**ì§ˆë¬¸:**\n{prompt}"}
    ]
    
    try:
        response = llm.invoke(messages)
        return response.content
    except Exception as e:
        return f"ì˜¤ë¥˜: {str(e)}"
